# Project 2: Cardiac Arrhythmia Multi-Class Classification 

Code Author: Anh Hong Le

#### Project Description:
- Analyze data and address missing data if there is any. 
- Decide aboute a good evaluation strategy and justify your choice. 
- Find the best parameters for the following classification models: 
    - KNN classifcation 
    - Logistic Regression
    - Linear Supprt Vector Machine
    - Kerenilzed Support Vector Machine
    - Decision Tree
    - Random Forest 


- Then use different bagging and boosting methods to boost the results? Do you see any significant change? Why or why not? 
- Next, use data reduction method you have learned in class to reduce the size of data, and agian try above models. Do you get better results? Justify your answer. 

#### Table of Contents
- Preamble and Datasets
- Part I: GridSeachCV, Bagging, Boosting, Voting Classifier
- Part II: Data Reduction ( Bagging/Boosting/Pure Estimators)
- Part III: Evaluation Strategy ( Recall and Micro-average)Â¶
- SUMMARY


# SUMMARY

 This summary is a brief guide to all justifications. Results in part III are based on test scores including out-of-bag outputs.

## Overall Performance

#### Best Performers

 Linear SVC is the best estimator among all algorithms in this project in term of Accuracy. However, in term of Recall, Random Forest has done the best job to recommend treatment to most people.

- Linear SVC scores highest in Bagging Ensemble with out-of-bag accuracy of 96% and  has the lowest of 76% with advanced methods
- Random Forest has the highest Recall of 88% among other estimators in pure method.

#### Medium Performers 
By descending maximum test score:

- Decision tree with Gradient Boosting( before PCA) scores the highest among the medium with 77%.

- Kernelized SVC in PCA and Random Forest in pure method both score 76%.

- Hard voting of pure estimators scores 75%.

- Logistic Regressor scores 73% in pure method. 

- Random Forest has maximum score of 72% in pure method, and generally worsened with all new methods including PCA. 

#### Low Performers
By descending maximum test score:

- K-Nearest Neighbor Classifier has the lowest score of 65%( in PCA), and can not be supported by Bagging/Boosting.


## Ensemble learning, Voting Classifier, and PCA
- In short, both bagging and boosting see signfinicant changes for all estimators. The reason is some estimators have done its best in training and testing; however, bagging/boosting even overfits the data as a whole. In this scenario, bagging works the best for Linear SVC, and boosting tremendously support decision tree.

- For PCA, results are almost equal on average compared to all estimators before data reduction. Bagging/boosting/voting with PCA do not optimize for the highest performance as existing in previous methods. In my opinion, the reason for no change is because PCA is not an appropriate method to capture the sigfificance of features for this dataset. Also, interdependency among variables is yet to be fully addressed in this project.

 #### Bagging:
- Improve the most with Linear SVC with 96%, and worsen Kernelized SVC with 54%.
#### Boosting:
- Gradient Boosting is a huge advantage for Decision Tree with 77% , and AdaBoost is the worst for Random Forest with 64% after PCA.
#### Hard Voting:
- The maximum score is 75% in pure method. The minimum score is 66% in both Boosting and Bagging( before PCA)
#### PCA:
- The maximum score is 76% Linear SVC and 74% for Kernel SVC in pure method. The worst is Kernelized SVC and Random Forest in Bagging Ensemble 54%.

## Evaluation Strategy 

- The accuracy is used in most methods of classfiers for simplicity of usage in comparing different method. Linear SVC seems to out perform other methods with 96 % out-of-bag score in Bagging ensemble.

- However, when it comes to situation when we wants to look at a different classification metric like Recall, Random Forest has proved to be the optimal one. In this imbalanced data, Random forest has highest score in Recall of 88% by Micro-average method. 

- The reason why I do not apply Bagging/Boosting/PCA in term of Recall is, generally, these methods on average have worsened performances as being seen with Accuracy.
